name: STEP Spatial Metadata Processor

on:
  push:
    branches:
      - "**"
  workflow_dispatch:

jobs:
  code_quality_check:
    runs-on: ubuntu-latest
    steps:
      - name: üõéÔ∏è Checkout repository
        uses: actions/checkout@v3

      - name: üêç Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: üêç Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: üßπ Run autoflake to remove unused imports
        run: |
          autoflake --in-place --recursive --remove-unused-variables --remove-all-unused-imports .
          
      - name: üíÄ Run vulture to find dead code
        run: |
          vulture --exclude .github,tests,data .
          
      - name: üöÄ Commit autoflake changes
        env:
          GIT_USER_NAME: ${{ secrets.GIT_USER_NAME }}
          GIT_USER_EMAIL: ${{ secrets.GIT_USER_EMAIL }}
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git add .
          git commit -m "üßπ Auto-clean: removed unused imports and variables" || echo "No changes to commit"
          git push || echo "No changes to push"

  process_step_for_coordinates:
    needs: code_quality_check
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: ${{ github.workspace }}
      ENABLE_RULE_DEBUG: true

    steps:
      - name: üõéÔ∏è Checkout repository
        uses: actions/checkout@v3

      - name: üêç Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: üß± Install system dependencies & Gmsh
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libglu1-mesa-dev \
            libfreetype6-dev \
            libfontconfig1-dev \
            libxrender1 \
            gmsh

      - name: üêç Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ‚úÖ Confirm Gmsh & Python bindings
        run: |
          gmsh -version || { echo "‚ùå Gmsh CLI not found"; exit 1; }
          python -c "import gmsh; gmsh.initialize(); gmsh.finalize(); print('‚úÖ Gmsh Python bindings operational')" || { echo "‚ùå Gmsh Python bindings failed"; exit 1; }
          
      # --- Integration Test moved here to fail fast ---
      - name: üèÉ Run Integration Tests (CLI Flow)
        run: |
          TEST_DIR="tests/test_models"
          
          # List all expected output files (etalons)
          ETALONS=$(find "$TEST_DIR" -maxdepth 1 -type f -name "*_output.json" -o -name "*_internal_output.json")
          
          if [ -z "$ETALONS" ]; then
            echo "No etalon JSON files found in $TEST_DIR. Skipping integration test."
            exit 0
          fi
          
          for ETALON_PATH in $ETALONS; do
            ETALON_FILENAME=$(basename "$ETALON_PATH")
            
            # Extract model name by removing common suffixes (e.g., '_internal_output.json' or '_output.json')
            MODEL_NAME=$(echo "$ETALON_FILENAME" | sed -E 's/(_internal|_external)?_output\.json$//')
            STEP_FILE="$TEST_DIR/$MODEL_NAME.step"
            TEMP_OUTPUT_FILE="$TEST_DIR/${MODEL_NAME}_CLI_output.json"
            
            # Skip if the corresponding STEP file doesn't exist
            if [ ! -f "$STEP_FILE" ]; then
              echo "‚ö†Ô∏è Skipping $MODEL_NAME: Corresponding STEP file not found."
              continue
            fi

            echo "--- Running integration test for: $MODEL_NAME (Etalon: $ETALON_FILENAME) ---"
            
            # --- Determine parameters (Assumes 0.01 resolution and infers flow region) ---
            RESOLUTION=0.01
            FLOW_REGION="internal"
            
            if [[ "$MODEL_NAME" == *"external"* ]]; then
              FLOW_REGION="external"
            fi
            
            # 1. Execute the full script via command line
            python3 src/gmsh_runner.py \
              --step "$STEP_FILE" \
              --resolution "$RESOLUTION" \
              --flow_region "$FLOW_REGION" \
              --output "$TEMP_OUTPUT_FILE"

            # 2. Compare the generated output with the etalon using Python for robust JSON comparison
            python3 -c "
              import json
              import sys
              from pathlib import Path

              etalon_path = Path('$ETALON_PATH')
              output_path = Path('$TEMP_OUTPUT_FILE')

              if not etalon_path.exists() or not output_path.exists():
                print(f'Error: Missing file for comparison. Etalon: {etalon_path.exists()}, Output: {output_path.exists()}')
                sys.exit(1)

              with open(etalon_path) as f:
                etalon = json.load(f)
              with open(output_path) as f:
                output = json.load(f)
              
              if etalon != output:
                # Note: The output check is strict equality. If floating-point differences 
                # cause failures, this check would need to be replaced with a comparison 
                # that uses a tolerance (e.g., NumPy comparison).
                print(f'‚ùå INTEGRATION TEST FAILED: Output mismatch for {etalon_path.name}')
                sys.exit(1)
              else:
                print(f'‚úÖ INTEGRATION TEST PASSED: {etalon_path.name} matches etalon.')
            "
            
            # Clean up temporary output file
            rm "$TEMP_OUTPUT_FILE"
          done
          echo "‚úÖ All Integration tests completed."
      # --- End of Integration Test block ---

      - name: ‚òÅÔ∏è Download & normalize STEP file
        env:
          APP_KEY: ${{ secrets.APP_KEY }}
          APP_SECRET: ${{ secrets.APP_SECRET }}
          REFRESH_TOKEN: ${{ secrets.REFRESH_TOKEN }}
        run: |
          chmod +x src/download_from_dropbox.sh
          src/download_from_dropbox.sh

          STEP_FILES=$(find data/testing-input-output -maxdepth 1 -type f -name "*.step")
          COUNT=$(echo "$STEP_FILES" | wc -l)
          if [ "$COUNT" -eq 0 ]; then
            echo "‚ùå No STEP file found. Cannot proceed."
            exit 1
          elif [ "$COUNT" -gt 1 ]; then
            echo "‚ö†Ô∏è Multiple STEP files found. Normalizing..."
            STEP_FILE=$(echo "$STEP_FILES" | head -n 1)
            mv "$STEP_FILE" data/testing-input-output/input.step
            echo "‚úÖ Normalized STEP file to input.step."
          else
            STEP_FILE=$(echo "$STEP_FILES")
            if [ "$STEP_FILE" != "data/testing-input-output/input.step" ]; then
              mv "$STEP_FILE" data/testing-input-output/input.step
              echo "‚úÖ Renamed $STEP_FILE to input.step"
            else
              echo "‚ÑπÔ∏è STEP file is already named input.step. No renaming needed."
            fi
          fi

      - name: üß† Extract config & run Gmsh
        run: |
          resolution=$(python -c "import json; print(json.load(open('data/testing-input-output/flow_data.json'))['model_properties']['default_resolution'])")
          flow_region=$(python -c "import json; print(json.load(open('data/testing-input-output/flow_data.json'))['model_properties']['flow_region'])")

          python3 src/gmsh_runner.py \
            --step data/testing-input-output/input.step \
            --resolution "$resolution" \
            --flow_region "$flow_region" \
            --output data/testing-input-output/geometry_masking_gmsh.json

      - name: üîç Validate output JSON against schema
        run: |
          python -c "
          import json, jsonschema
          from pathlib import Path
          output_path = Path('data/testing-input-output/geometry_masking_gmsh.json')
          if not output_path.exists():
            raise FileNotFoundError(f'Schema validation failed ‚Äî file not found: {output_path}')
          with open('schemas/domain_schema.json') as s, open(output_path) as d:
            schema = json.load(s)
            data = json.load(d)
            jsonschema.validate(instance=data, schema=schema)
          "
          echo "‚úÖ Output schema validated"

      - name: üß™ Run Unit Tests with Coverage
        run: |
          pytest --cov=src --cov-report=term-missing
          echo "‚úÖ Unit tests and code coverage check completed."

      - name: ‚òÅÔ∏è Upload outputs to Dropbox
        env:
          APP_KEY: ${{ secrets.APP_KEY }}
          APP_SECRET: ${{ secrets.APP_SECRET }}
          REFRESH_TOKEN: ${{ secrets.REFRESH_TOKEN }}
        run: |
          chmod +x src/upload_to_dropbox.sh
          src/upload_to_dropbox.sh

      - name: üìù Log trigger & push
        env:
          GIT_USER_NAME: ${{ secrets.GIT_USER_NAME }}
          GIT_USER_EMAIL: ${{ secrets.GIT_USER_EMAIL }}
        run: |
          echo "$(date '+%Y-%m-%d %H:%M:%S'): STEP processor triggered by '${{ github.actor }}' via '${{ github.event_name }}' event" >> trigger.txt
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git pull --rebase origin main || echo "‚ö†Ô∏è Pull failed or not needed"
          git add trigger.txt
          git commit -m "Log STEP processor trigger by ${{ github.actor }} via ${{ github.event_name }}"
          git push



