# üìÑ .github/workflows/STEP Spatial Metadata Processor.yml

name: STEP Spatial Metadata Processor

on:
  push:
    branches:
      - "**"
  workflow_dispatch:

jobs:
  process_step_for_coordinates:
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: ${{ github.workspace }}
      ENABLE_RULE_DEBUG: true

    steps:
      - name: üõéÔ∏è Checkout repository
        uses: actions/checkout@v3

      - name: üêç Set Python version
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: üß± Install system dependencies (Gmsh, Qt, etc.)
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libglu1-mesa-dev \
            libfreetype6-dev \
            libfontconfig1-dev \
            libxrender1 \
            gmsh

      - name: üêç Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: üîç Verify Gmsh version
        run: python -c "import gmsh; print('Gmsh version:', gmsh.__version__)"

      - name: ‚úÖ Verify installed packages
        run: |
          pip freeze
          pip check

      - name: üß™ Confirm Gmsh availability for tests
        run: |
          echo "üîç Checking Gmsh CLI and Python bindings..."
          gmsh -version || { echo "‚ùå Gmsh CLI not found"; exit 1; }
          python -c "import gmsh; gmsh.initialize(); gmsh.finalize(); print('‚úÖ Gmsh Python bindings operational')" || { echo "‚ùå Gmsh Python bindings failed"; exit 1; }

      - name: üßπ Clear simulation output artifacts
        run: |
          rm -rf "$GITHUB_WORKSPACE/data/testing-input-output/"*
          echo "‚úÖ Output directories cleaned"

      - name: ‚úÖ Make Dropbox download script executable
        run: chmod +x src/download_from_dropbox.sh

      - name: ‚òÅÔ∏è Download simulation files from Dropbox
        env:
          APP_KEY: ${{ secrets.APP_KEY }}
          APP_SECRET: ${{ secrets.APP_SECRET }}
          REFRESH_TOKEN: ${{ secrets.REFRESH_TOKEN }}
        run: src/download_from_dropbox.sh

      - name: üîé Normalize STEP filename
        run: |
          STEP_FILES=$(find data/testing-input-output -maxdepth 1 -type f -name "*.step")
          COUNT=$(echo "$STEP_FILES" | wc -l)

          if [ "$COUNT" -eq 0 ]; then
            echo "‚ùå No STEP file found. Cannot proceed."
            exit 1
          elif [ "$COUNT" -gt 1 ]; then
            echo "‚ö†Ô∏è Multiple STEP files found. Checking for input.step to clean up..."
            echo "$STEP_FILES" | grep "input.step" | while read INPUT_FILE; do
              echo "üßπ Deleting redundant STEP file: $INPUT_FILE"
              rm -f "$INPUT_FILE"
            done
            STEP_FILES=$(find data/testing-input-output -maxdepth 1 -type f -name "*.step")
            COUNT=$(echo "$STEP_FILES" | wc -l)

            if [ "$COUNT" -eq 1 ]; then
              STEP_FILE=$(echo "$STEP_FILES")
              mv "$STEP_FILE" data/testing-input-output/input.step
              echo "‚úÖ Normalized STEP file: $STEP_FILE ‚Üí input.step"
            elif [ "$COUNT" -eq 0 ]; then
              echo "‚ùå No STEP file found after cleanup."
              exit 1
            else
              echo "‚ùå Still multiple STEP files found after input.step cleanup:"
              echo "$STEP_FILES"
              exit 1
            fi
          else
            STEP_FILE=$(echo "$STEP_FILES")
            if [ "$STEP_FILE" != "data/testing-input-output/input.step" ]; then
              mv "$STEP_FILE" data/testing-input-output/input.step
              echo "‚úÖ Renamed $STEP_FILE to input.step"
            else
              echo "‚ÑπÔ∏è STEP file is already named input.step. No renaming needed."
            fi
          fi

      - name: üß† Extract resolution and flow_region from flow_data.json
        id: extract_config
        run: |
          echo "Reading resolution and flow_region from flow_data.json..."
          RESOLUTION=$(python -c "import json; print(json.load(open('data/testing-input-output/flow_data.json'))['model_properties']['default_resolution'])")
          FLOW_REGION=$(python -c "import json; print(json.load(open('data/testing-input-output/flow_data.json'))['model_properties']['flow_region'])")
          echo "Extracted resolution: $RESOLUTION"
          echo "Extracted flow_region: $FLOW_REGION"
          echo "resolution=$RESOLUTION" >> $GITHUB_ENV
          echo "flow_region=$FLOW_REGION" >> $GITHUB_ENV

      - name: üìè Print extracted configuration values
        run: |
          echo "‚úÖ Configuration extracted from flow_data.json:"
          echo "Resolution = ${{ env.resolution }} meters"
          echo "Flow Region = ${{ env.flow_region }}"

      - name: üß† Run domain extraction via Gmsh CLI module
        run: |
          python3 src/gmsh_runner.py \
            --step data/testing-input-output/input.step \
            --resolution ${{ env.resolution }} \
            --flow_region ${{ env.flow_region }} \
            --output data/testing-input-output/geometry_masking_gmsh.json

      - name: üîç Validate output JSON against schema
        run: |
          python -c "
          import json, jsonschema
          from pathlib import Path
          output_path = Path('data/testing-input-output/geometry_masking_gmsh.json')
          if not output_path.exists():
              raise FileNotFoundError(f'Schema validation failed ‚Äî file not found: {output_path}')
          with open('schemas/domain_schema.json') as s, open(output_path) as d:
              schema = json.load(s)
              data = json.load(d)
              jsonschema.validate(instance=data, schema=schema)
          "
          echo "‚úÖ Output schema validated"

      - name: üîç Print sys.path for module discovery insight
        run: python -c "import sys; print('PYTHON sys.path:', sys.path)"

      - name: üß™ Sanity check - validate 'is_literal' import
        run: |
          echo "üîé Verifying that 'is_literal' is discoverable and functional..."
          python -c "from src.validation.expression_utils import is_literal; print('Sample result:', is_literal('123'))"
          echo "‚úÖ Import check passed. Proceeding to full test suite."

      - name: üßπ Purge stale compiled Python artifacts
        run: |
          echo "üßπ Removing __pycache__ and *.pyc files across workspace..."
          find $GITHUB_WORKSPACE -type d -name "__pycache__" -exec rm -rf {} +
          find $GITHUB_WORKSPACE -type f -name "*.pyc" -delete
          echo "‚úÖ Cleared cached Python artifacts"

      - name: üöÄ Print relaxed-mode test confirmation
        run: |
          echo "üß™ Ensuring relaxed-mode rule tests are captured..."
          grep -r "type_check_mode.*relaxed" tests/rules/test_rule_engine_integration.py || echo "‚ö†Ô∏è No relaxed-mode tests found"

      - name: üß™ Run Unit Tests
        run: |
          pytest -s tests/ --verbose -ra
          echo "‚úÖ Unit tests completed."

      - name: üß≠ Debug directory tree
        run: ls -R $GITHUB_WORKSPACE

      - name: ‚úÖ Make upload script executable
        run: chmod +x src/upload_to_dropbox.sh

      - name: ‚òÅÔ∏è Upload outputs to Dropbox
        env:
          APP_KEY: ${{ secrets.APP_KEY }}
          APP_SECRET: ${{ secrets.APP_SECRET }}
          REFRESH_TOKEN: ${{ secrets.REFRESH_TOKEN }}
        run: src/upload_to_dropbox.sh

      - name: üìù Log trigger for STEP processor
        run: |
          echo "$(date '+%Y-%m-%d %H:%M:%S'): STEP processor triggered by '${{ github.actor }}' via '${{ github.event_name }}' event" >> trigger.txt

      - name: üöÄ Commit and push trigger log
        env:
          GIT_USER_NAME: ${{ secrets.GIT_USER_NAME }}
          GIT_USER_EMAIL: ${{ secrets.GIT_USER_EMAIL }}
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git pull --rebase origin main || echo "‚ö†Ô∏è Pull failed or not needed"
          git add trigger.txt
          git commit -m "Log STEP processor trigger by ${{ github.actor }} via ${{ github.event_name }}"
          git push




