name: STEP Spatial Metadata Processor

on:
  push:
    branches:
      - "**"
  workflow_dispatch:

jobs:
  code_quality_check:
    runs-on: ubuntu-latest
    steps:
      - name: üõéÔ∏è Checkout repository
        uses: actions/checkout@v3

      - name: üêç Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: üêç Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: üßπ Run autoflake to remove unused imports
        run: |
          autoflake --in-place --recursive --remove-unused-variables --remove-all-unused-imports .
          
      - name: üíÄ Run vulture to find dead code
        run: |
          vulture --exclude .github,tests,data .
          
      - name: üöÄ Commit autoflake changes
        env:
          GIT_USER_NAME: ${{ secrets.GIT_USER_NAME }}
          GIT_USER_EMAIL: ${{ secrets.GIT_USER_EMAIL }}
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git add .
          git commit -m "üßπ Auto-clean: removed unused imports and variables" || echo "No changes to commit"
          git push || echo "No changes to push"

  process_step_for_coordinates:
    needs: code_quality_check
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: ${{ github.workspace }}
      ENABLE_RULE_DEBUG: true

    steps:
      - name: üõéÔ∏è Checkout repository
        uses: actions/checkout@v3

      - name: üêç Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: üß± Install system dependencies & Gmsh
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libglu1-mesa-dev \
            libfreetype6-dev \
            libfontconfig1-dev \
            libxrender1 \
            gmsh

      - name: üêç Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ‚úÖ Confirm Gmsh & Python bindings
        run: |
          gmsh -version || { echo "‚ùå Gmsh CLI not found"; exit 1; }
          python -c "import gmsh; gmsh.initialize(); gmsh.finalize(); print('‚úÖ Gmsh Python bindings operational')" || { echo "‚ùå Gmsh Python bindings failed"; exit 1; }
          
      - name: üèÉ Run Integration Test (test_cube)
        run: |
          # All paths for the specific test case (test_cube)
          STEP_FILE="tests/test_models/test_cube.step"
          EXPECTED_OUTPUT_PATH="tests/test_models/test_cube_output.json"
          TEMP_OUTPUT_FILE="tests/test_models/test_cube_cli_output.json"
          
          # Check for mandatory input files
          if [ ! -f "$STEP_FILE" ]; then
            echo "‚ùå Fatal Error: STEP file ($STEP_FILE) not found. Cannot run integration test."
            exit 1
          fi
          if [ ! -f "$EXPECTED_OUTPUT_PATH" ]; then
            echo "‚ùå Fatal Error: Expected Output file ($EXPECTED_OUTPUT_PATH) not found. Cannot run integration test."
            exit 1
          fi

          echo "--- Running simplified integration test for: test_cube (Expected Output: $EXPECTED_OUTPUT_PATH) ---"
          
          # --- Set fixed parameters for test_cube ---
          RESOLUTION=0.01
          FLOW_REGION="internal"
          
          # 1. Execute the full script via command line
          python3 src/gmsh_runner.py \
            --step "$STEP_FILE" \
            --resolution "$RESOLUTION" \
            --flow_region "$FLOW_REGION" \
            --output "$TEMP_OUTPUT_FILE"

          # 2. Compare the generated output with the expected output, printing a diff on failure
          python3 -c "
            import json
            import sys
            from pathlib import Path
            import difflib # Added difflib for diff generation

            expected_path = Path('$EXPECTED_OUTPUT_PATH')
            output_path = Path('$TEMP_OUTPUT_FILE')

            try:
              with open(expected_path) as f:
                expected = json.load(f)
              with open(output_path) as f:
                output = json.load(f)
            except FileNotFoundError:
              print(f'‚ùå INTEGRATION TEST FAILED: Missing generated output file {output_path.name}.')
              sys.exit(1)
            except json.JSONDecodeError:
              print(f'‚ùå INTEGRATION TEST FAILED: Generated output file {output_path.name} is invalid JSON.')
              sys.exit(1)
            
            # --- Check for mismatch and print diff ---
            if expected != output:
              # Convert dicts to sorted, indented JSON strings for stable line-by-line diff
              expected_str = json.dumps(expected, indent=2, sort_keys=True)
              output_str = json.dumps(output, indent=2, sort_keys=True)

              diff = difflib.unified_diff(
                  expected_str.splitlines(keepends=True),
                  output_str.splitlines(keepends=True),
                  fromfile=expected_path.name,
                  tofile=output_path.name,
                  lineterm=''
              )
              
              print(f'‚ùå INTEGRATION TEST FAILED: Output mismatch for {expected_path.name}')
              print('\n--- JSON DIFF (Expected vs Generated) ---')
              sys.stdout.writelines(diff)
              print('--------------------------------------\n')
              
              # Clean up temporary output file before exiting on failure
              output_path.unlink(missing_ok=True)
              sys.exit(1)
            else:
              print(f'‚úÖ INTEGRATION TEST PASSED: {expected_path.name} matches expected output.')
          "
          
          # Clean up temporary output file on success
          rm "$TEMP_OUTPUT_FILE"
          echo "‚úÖ Simplified Integration test completed."

      - name: ‚òÅÔ∏è Download & normalize STEP file
        env:
          APP_KEY: ${{ secrets.APP_KEY }}
          APP_SECRET: ${{ secrets.APP_SECRET }}
          REFRESH_TOKEN: ${{ secrets.REFRESH_TOKEN }}
        run: |
          chmod +x src/download_from_dropbox.sh
          src/download_from_dropbox.sh

          STEP_FILES=$(find data/testing-input-output -maxdepth 1 -type f -name "*.step")
          COUNT=$(echo "$STEP_FILES" | wc -l)
          if [ "$COUNT" -eq 0 ]; then
            echo "‚ùå No STEP file found. Cannot proceed."
            exit 1
          elif [ "$COUNT" -gt 1 ]; then
            echo "‚ö†Ô∏è Multiple STEP files found. Normalizing..."
            STEP_FILE=$(echo "$STEP_FILES" | head -n 1)
            mv "$STEP_FILE" data/testing-input-output/input.step
            echo "‚úÖ Normalized STEP file to input.step."
          else
            STEP_FILE=$(echo "$STEP_FILES")
            if [ "$STEP_FILE" != "data/testing-input-output/input.step" ]; then
              mv "$STEP_FILE" data/testing-input-output/input.step
              echo "‚úÖ Renamed $STEP_FILE to input.step"
            else
              echo "‚ÑπÔ∏è STEP file is already named input.step. No renaming needed."
            fi
          fi

      - name: üß† Extract config & run Gmsh
        run: |
          resolution=$(python -c "import json; print(json.load(open('data/testing-input-output/flow_data.json'))['model_properties']['default_resolution'])")
          flow_region=$(python -c "import json; print(json.load(open('data/testing-input-output/flow_data.json'))['model_properties']['flow_region'])")

          python3 src/gmsh_runner.py \
            --step data/testing-input-output/input.step \
            --resolution "$resolution" \
            --flow_region "$flow_region" \
            --output data/testing-input-output/geometry_masking_gmsh.json

      - name: üîç Validate output JSON against schema
        run: |
          python -c "
          import json, jsonschema
          from pathlib import Path
          output_path = Path('data/testing-input-output/geometry_masking_gmsh.json')
          if not output_path.exists():
            raise FileNotFoundError(f'Schema validation failed ‚Äî file not found: {output_path}')
          with open('schemas/domain_schema.json') as s, open(output_path) as d:
            schema = json.load(s)
            data = json.load(d)
            jsonschema.validate(instance=data, schema=schema)
          "
          echo "‚úÖ Output schema validated"

      - name: üß™ Run Unit Tests with Coverage
        run: |
          pytest --cov=src --cov-report=term-missing
          echo "‚úÖ Unit tests and code coverage check completed."

      - name: ‚òÅÔ∏è Upload outputs to Dropbox
        env:
          APP_KEY: ${{ secrets.APP_KEY }}
          APP_SECRET: ${{ secrets.APP_SECRET }}
          REFRESH_TOKEN: ${{ secrets.REFRESH_TOKEN }}
        run: |
          chmod +x src/upload_to_dropbox.sh
          src/upload_to_dropbox.sh

      - name: üìù Log trigger & push
        env:
          GIT_USER_NAME: ${{ secrets.GIT_USER_NAME }}
          GIT_USER_EMAIL: ${{ secrets.GIT_USER_EMAIL }}
        run: |
          echo "$(date '+%Y-%m-%d %H:%M:%S'): STEP processor triggered by '${{ github.actor }}' via '${{ github.event_name }}' event" >> trigger.txt
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git pull --rebase origin main || echo "‚ö†Ô∏è Pull failed or not needed"
          git add trigger.txt
          git commit -m "Log STEP processor trigger by ${{ github.actor }} via ${{ github.event_name }}"
          git push



